{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SoC Conversational Chatbot.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPfrMXfI2iuaEfyBKM6ID2B"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"gmDgxzuW-dwR","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","import re"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qys-CEEVi3JO","colab_type":"code","outputId":"42f8ba35-524e-4e09-e352-4eb20b9a07c2","executionInfo":{"status":"error","timestamp":1588758386374,"user_tz":-330,"elapsed":1845,"user":{"displayName":"Pranjal Gupta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNVJfplYMVPSCrzfgmZs4KqqQOC2FWAqE04aFj=s64","userId":"05378046480422567758"}},"colab":{"base_uri":"https://localhost:8080/","height":252}},"source":["#reading data from the movie_conversations.txt file\n","movie_conversations = open('movie_conversations.txt','r')\n","conversations = []    #contains all the conversations as list elements ( list within a list )\n","for i in movie_conversations.readlines():\n","  a = i.split('+++$+++')\n","  b = a[4].split(', ') \n","  conv= []\n","  for j in b:\n","    conv.append(re.sub(r'[^\\w]', ' ',j).replace(\" \",\"\"))\n","  conversations.append(conv)\n","conversations[:5]"],"execution_count":13,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-54f99dc4c27f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmovie_conversations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'+++$+++'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m', '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mconv\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"code","metadata":{"id":"BOxom6VHu7zA","colab_type":"code","colab":{}},"source":["#reading data from the movie_lines.txt\n","movie_lines = open('movie_lines.txt','rb')\n","code_vs_dialogue_list = dict()\n","for line in movie_lines:\n","  i = line.decode(encoding='utf-8',errors='ignore')\n","  a = i.split('+++$+++')\n","  conv_code = a[0].replace(\" \",\"\")\n","  dialogue = a[3].replace(\"\\n\",\"\").strip()\n","  code_vs_dialogue_list.update({conv_code:dialogue})\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l2w0KKfy4pdk","colab_type":"code","colab":{}},"source":["def find_dialogue(x):\n","    return code_vs_dialogue_list[x]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VeMr859C9e7C","colab_type":"code","colab":{}},"source":["questions = []\n","answers = []\n","for i in conversations:\n","  for k in range(len(i)-1):\n","    questions.append(find_dialogue(i[k]))\n","    answers.append(find_dialogue(i[k+1])) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pmr9gf5fgvS6","colab_type":"code","colab":{}},"source":["answers_with_tags = []\n","for i in range( len( answers ) ):\n","    if type( answers[i] ) == str:\n","        answers_with_tags.append( '<START> ' + answers[i] + ' <END>' )\n","    else:\n","        questions.pop( i )\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fJ3dwgsuushn","colab_type":"code","colab":{}},"source":["#questions = questions[:1000]\n","#answers_with_tags = answers_with_tags[:1000]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kQXUaCilg5DW","colab_type":"code","colab":{}},"source":["tokenizer = tf.keras.preprocessing.text.Tokenizer()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W3wbYs39g6Dt","colab_type":"code","colab":{}},"source":["tokenizer.fit_on_texts(questions + answers_with_tags)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G583aXfNg9lK","colab_type":"code","colab":{}},"source":["vocab_size = len(tokenizer.word_index) + 1\n","vocab_size"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pd0QjHcXNojH","colab_type":"code","colab":{}},"source":["upper_limit = 10\n","tokenized_questions = tokenizer.texts_to_sequences(questions)\n","tokenized_answers = tokenizer.texts_to_sequences( answers_with_tags )\n","final_tokens_questions = []\n","final_tokens_answers = []\n","for i in range(len(tokenized_questions)):\n","  if len(tokenized_questions[i])<=upper_limit:\n","    final_tokens_questions.append(tokenized_questions[i])\n","    final_tokens_answers.append(tokenized_answers[i])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dAE3tFabRdDT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":361},"outputId":"41bb68cb-3361-45c1-f6e4-f9ca0481cd9a","executionInfo":{"status":"error","timestamp":1588689756859,"user_tz":-330,"elapsed":1076,"user":{"displayName":"Pranjal Gupta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNVJfplYMVPSCrzfgmZs4KqqQOC2FWAqE04aFj=s64","userId":"05378046480422567758"}}},"source":[""],"execution_count":13,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-7fd012b02b5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_tokens_questions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfinal_tokens_answers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mfit_on_texts\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext_elem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext_elem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext_elem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext_elem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'lower'"]}]},{"cell_type":"code","metadata":{"id":"r5O7EG8Pg93Y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"24061a74-342a-401f-a3df-bc0690ac0fca","executionInfo":{"status":"ok","timestamp":1588689292547,"user_tz":-330,"elapsed":1538,"user":{"displayName":"Pranjal Gupta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNVJfplYMVPSCrzfgmZs4KqqQOC2FWAqE04aFj=s64","userId":"05378046480422567758"}}},"source":["#encoder_input_data_preprocessing\n","#maxlen_questions = max( [ len(x) for x in tokenized_questions ] )\n","#padded_questions = tf.keras.preprocessing.sequence.pad_sequences( tokenized_questions , maxlen=maxlen_questions , padding='post' )\n","padded_questions = tf.keras.preprocessing.sequence.pad_sequences( final_tokens_questions , maxlen=upper_limit , padding='post' )\n","encoder_input_data = np.array( padded_questions )\n","print( encoder_input_data.shape )"],"execution_count":13,"outputs":[{"output_type":"stream","text":["(151057, 10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Zg7d6IlhhI6V","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b20c206f-64e8-4bd6-b49b-c2baa0056ef8","executionInfo":{"status":"ok","timestamp":1588689293424,"user_tz":-330,"elapsed":1672,"user":{"displayName":"Pranjal Gupta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNVJfplYMVPSCrzfgmZs4KqqQOC2FWAqE04aFj=s64","userId":"05378046480422567758"}}},"source":["# decoder_input_data\n","#tokenized_answers = tokenizer.texts_to_sequences( answers_with_tags )\n","#maxlen_answers = max( [ len(x) for x in tokenized_answers ] )\n","padded_answers = tf.keras.preprocessing.sequence.pad_sequences( final_tokens_answers , maxlen=upper_limit , padding='post' )\n","decoder_input_data = np.array( padded_answers )\n","print( decoder_input_data.shape  )"],"execution_count":14,"outputs":[{"output_type":"stream","text":["(151057, 10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VJQ5yrMCThU0","colab_type":"code","colab":{}},"source":["for i in range(len(final_tokens_answers)) :\n","    final_tokens_answers[i] = final_tokens_answers[i][1:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zi6gnpNshJOx","colab_type":"code","colab":{}},"source":["# decoder_output_data\n","#tokenized_answers = tokenizer.texts_to_sequences( answers_with_tags )\n","\n","#maxlen_answers = max( [ len(x) for x in tokenized_answers ] )\n","padded_answers = tf.keras.preprocessing.sequence.pad_sequences( final_tokens_answers , maxlen= upper_limit, padding='post' )\n","onehot_answers = tf.keras.utils.to_categorical( padded_answers , vocab_size )\n","decoder_output_data = np.array( onehot_answers )\n","print( decoder_output_data.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U4vjQ_puSlZ2","colab_type":"code","colab":{}},"source":["#Hyperparameters\n","##vocab_size = 1000\n","embedding_dim = 256\n","batch_size = 32\n","#input_length = 10\n","lstm_units = 1024\n","#encoder_input_training_data = tf.keras.layers.Input(shape=(None, ))\n","#decoder_input_training_data = tf.keras.layers.Input(shape=(None, ))\n","#decoder_output_training_data = tf.keras.layers.Input(shape=(None, ))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ExrjUalV-jmR","colab_type":"code","outputId":"a30b8952-00c4-4c19-fa95-7bf3ad4768cf","executionInfo":{"status":"ok","timestamp":1588681303662,"user_tz":-330,"elapsed":5536,"user":{"displayName":"Pranjal Gupta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNVJfplYMVPSCrzfgmZs4KqqQOC2FWAqE04aFj=s64","userId":"05378046480422567758"}},"colab":{"base_uri":"https://localhost:8080/","height":445}},"source":["#training cell with training model created.\n","inference_encoder_inputs = tf.keras.layers.Input(shape=(None,)) #'''batch_size=batch_size''' )\n","embedded_encoder_inputs = tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True)(inference_encoder_inputs)\n","encoder_output,state_h,state_c = tf.keras.layers.LSTM(lstm_units, return_state=True)(embedded_encoder_inputs) # '''input_shape=(batch_size,input_length,embedding_dim)'''\n","encoder_states = [state_h,state_c]\n","\n","inference_decoder_inputs = tf.keras.layers.Input(shape=(None,)) #''',batch_size=batch_size''')\n","embedded_decoder_inputs = tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True)(inference_decoder_inputs)\n","decoder_lstm_layer = tf.keras.layers.LSTM(lstm_units, return_state = True, return_sequences=True) #''',input_shape=(batch_size,input_length,embedding_dim)'''\n","decoder_output,_,_ = decoder_lstm_layer(embedded_decoder_inputs, initial_state = encoder_states)\n","dense_layer = tf.keras.layers.Dense(vocab_size, activation=tf.keras.activations.softmax)\n","decoder_output = dense_layer(decoder_output)\n","\n","training_model = tf.keras.models.Model([inference_encoder_inputs,inference_decoder_inputs],decoder_output)\n","training_model.compile(optimizer = tf.keras.optimizers.RMSprop(), loss = 'categorical_crossentropy')\n","\n","training_model.summary()\n","\n","# Some important points - \n","# raw inputs and outputs are used to define the model ( without embedding ). \n","# NEVER overwrite tensors, because the LSTM layer requires brand new embedded layer\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, None, 256)    593152      input_1[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, None, 256)    593152      input_2[0][0]                    \n","__________________________________________________________________________________________________\n","lstm (LSTM)                     [(None, 1024), (None 5246976     embedding[0][0]                  \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   [(None, None, 1024), 5246976     embedding_1[0][0]                \n","                                                                 lstm[0][1]                       \n","                                                                 lstm[0][2]                       \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, None, 2317)   2374925     lstm_1[0][0]                     \n","==================================================================================================\n","Total params: 14,055,181\n","Trainable params: 14,055,181\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lmDAIisID7TF","colab_type":"code","outputId":"76fdc884-cba5-4f2e-a9c3-de6eb8ecc86c","executionInfo":{"status":"ok","timestamp":1588681548503,"user_tz":-330,"elapsed":239050,"user":{"displayName":"Pranjal Gupta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNVJfplYMVPSCrzfgmZs4KqqQOC2FWAqE04aFj=s64","userId":"05378046480422567758"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["training_model.fit([encoder_input_data,decoder_input_data],decoder_output_data,batch_size=32, epochs = 1)\n","training_model.save('trainingmodel.h5')"],"execution_count":17,"outputs":[{"output_type":"stream","text":["32/32 [==============================] - 224s 7s/step - loss: 0.5335\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T8zMg6amEACi","colab_type":"code","colab":{}},"source":["def make_inference_models():\n","  inference_encoder_model = tf.keras.models.Model(inference_encoder_inputs,encoder_states)\n","\n","  decoder_state_input_h = tf.keras.layers.Input(shape=(lstm_units, ))\n","  decoder_state_input_c = tf.keras.layers.Input(shape=(lstm_units, ))\n","  decoder_states_inputs = [decoder_state_input_h,decoder_state_input_c]\n","\n","  decoder_output,state_h,state_c = decoder_lstm_layer(embedded_decoder_inputs, initial_state = decoder_states_inputs)\n","  decoder_states = [state_h,state_c]\n","  decoder_output = dense_layer(decoder_output)\n","\n","  inference_decoder_model = tf.keras.models.Model([inference_decoder_inputs]+decoder_states_inputs, [decoder_output]+decoder_states)\n","\n","  return inference_encoder_model,inference_decoder_model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UINCywCgeijR","colab_type":"code","colab":{}},"source":["def str_to_tokens( sentence : str ):\n","    words = sentence.lower().split()\n","    tokens_list = list()\n","    for word in words:\n","        tokens_list.append( tokenizer.word_index[ word ] ) \n","    return tf.keras.preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=maxlen_questions , padding='post')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V8y_02Hwzz7w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":439},"outputId":"91d42192-d64e-4f11-ca75-c8d7fe4e90ee","executionInfo":{"status":"error","timestamp":1588682120532,"user_tz":-330,"elapsed":29966,"user":{"displayName":"Pranjal Gupta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjNVJfplYMVPSCrzfgmZs4KqqQOC2FWAqE04aFj=s64","userId":"05378046480422567758"}}},"source":["enc_model , dec_model = make_inference_models()\n","\n","for _ in range(10):\n","    states_values = enc_model.predict( str_to_tokens( input( 'Enter question : ' ) ) )\n","    empty_target_seq = np.zeros( ( 1 , 1 ) )\n","    empty_target_seq[0, 0] = tokenizer.word_index['start']\n","    stop_condition = False\n","    decoded_translation = ''\n","    while not stop_condition :\n","        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n","        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n","        sampled_word = None\n","        for word , index in tokenizer.word_index.items() :\n","            if sampled_word_index == index :\n","                decoded_translation += ' {}'.format( word )\n","                sampled_word = word\n","        \n","        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n","            stop_condition = True\n","            \n","        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n","        empty_target_seq[ 0 , 0 ] = sampled_word_index\n","        states_values = [ h , c ] \n","\n","    print( decoded_translation )"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Enter question : How are you \n"," you end\n","Enter question : hi\n"," you end\n","Enter question : hello\n"],"name":"stdout"},{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-a3576c66748e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mstates_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mstr_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'Enter question : '\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mempty_target_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mempty_target_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-86e938c7c03c>\u001b[0m in \u001b[0;36mstr_to_tokens\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtokens_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtokens_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mword\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokens_list\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen_questions\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'hello'"]}]},{"cell_type":"code","metadata":{"id":"Obx7BGtK0Ktg","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}